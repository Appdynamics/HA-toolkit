Contents:

	README: this file
	RUNBOOK:  a list of state descriptions, validations, and remedial actions


	replicate.sh:  the all-singing, all-dancing HA (re)activator
	this installs and sets up the HA function for a controller pair.

	appdcontroller.sh: a file intended to be placed into /etc/init.d to control
	the controller, watchdog, and assassin

	appdcontroller-db.sh: a file intended to be placed into /etc/init.d to control
	the mysql database

	assassin.sh:  a script run on a failed-over primary to kill the old primary

	failover.sh:  a script run on a secondary to become the new primary

	install-init.sh:  an installer for the appdcontroller.sh

	uninstall-init.sh:  an uninstaller for the appdcontroller.sh

	watchdog.sh:  run on a secondary to watch the primary and maybe failover

	watchdog.settings.template:  copy this to watchdog.settings to override defaults

	appdservice-root.sh:  a null privilege escalation wrapper

	appdservice-pbrun.sh:  a privilege escalation wrapper around pbrun

	appdservice.c:  a privilege escalation c program
	
Installation notes:
This software is intended to connect the appdynamics controller into linux's
service machinery.  This optionally includes a watchdog process running on the
secondary HA node that will initiate a failover if a failure is detected in
the primary controller or database.

Permissions: 
	If the controller is to be run as a non-root user, part of the 
installation cannot be directly automated, as it involves installing of a 
system service into /etc/init.d and ancillary directories using install-init.sh

Prerequisites:
--------------
	1) Ssh must be installed in such a way that the user the controller is to 
be run as has symmetrical passwordless ssh access.  This is done by generating 
a key pair on each node, and placing the other's public key into the appropriate
authorized_keys file.  in detail, assuming user appduser, node1 and node2

	on node1:

	su - appduser
	mkdir -p .ssh
	ssh-keygen -t rsa -N "" -f .ssh/id_rsa
	scp .ssh/id_rsa.pub node2:/tmp

	on node2:

	su - appduser
	mkdir -p .ssh
	ssh-keygen -t rsa -N "" -f .ssh/id_rsa
	cat /tmp/id_rsa.pub >> .ssh/authorized_keys
	scp .ssh/id_rsa.pub node1:/tmp

	on node1:
	cat /tmp/id_rsa.pub >> ~/.ssh/authorized_keys

All of the above commands may not be needed, and some of them may prompt for a
password.

	2) reliable symmetrical reverse host lookup must be configured.  the best
way is to place the host names into each /etc/hosts file.   reverse DNS adds 
an additional point of failure.  
		a) /etc/nsswitch.conf should have files placed before dns. example:
			hosts:      files dns
		b) /etc/hosts:
			192.168.144.128 host1
			192.168.144.137 host2

	3) each machine must have the root and data directory writable by the 
appropriate appdynamics user:

	ls -lad /opt/AppDynamics/Controller
drwxr-xr-x. 18 appduser users    4096 Jan 26 18:18 /opt/AppDynamics/Controller

	4) the primary controller should be installed as a standalone controller;
the secondary should not be installed at all.

Installation:
-------------
On the primary, unpack the shar file using bash into a directory HA under the 
controller root install subdirectory.

	cd /opt/AppDynamics/Controller
	mkdir -p HA
	chmod +w *
	bash HA.shar

Activation:
-----------
The key script to replicate the primary database to the secondary, make all the
appropriate state changes, and activate the HA pair is the replicate.sh script.
it is run on an active controller.  Attempts to run it on a passive controller 
will be rejected.  it has a few specialized options, but it has reasonable
defaults and is extracts a lot of configuration information from the existing
installation.  the most simple usage is to activate a HA pair immediately.
run the following as the same user as appdynamics is running as.
since the controller is taken down, the command will prompt for a confirmation message.

	./replicate.sh -s node2 -f -w -e proxy

when it has completed, the HA pair will be running and replicating.
If running as non-root, the command asks that some commands manually be run as
root to complete the installation.

Incremental Activation:
-----------------------
Runs of the replicate script without the -f option will perform an imperfect 
copy of the primary controller to the secondary without taking the primary down.
This can be used to minimize the downtime necessary to do the initial 
installation.  if the data volume to replicate is large, several runs without
the -f option would approach a perfect copy over a period of days.  the final
activation with -f during a maintenance window would only copy those data filesi
that differ from the last copy.

Privilege Escalation:
---------------------
the install-init.sh script is used to install the init scripts, and to set
up a controlled privilege escalation.  this can take the form of sudo settings,
or one of 3 flavors of /sbin/appdservice. run install-init.sh for usage.

Service Control:
----------------
After activation, the controller service and HA facility can be controlled 
using the linux service command.  these options must be executed as root.
The default installation will automatically shut down the controller when
the system is halted, and automatically start it at boot time.

	service appdcontroller start
	service appdcontroller stop

an additional service, appdcontroller-db, is used to manage the database.
a sensible dependency between the two services is implemented

Status:
-------
Once installed as a service, the linux service utility can be run on either
node to report the current state of the replication, background processes, and
the controller itself.

	service appdcontroller status

Watchdog:
---------
If enabled, this background process running on the secondary will monitor the
primary controller and database, and if it detects a failure, will initiate a
failover automatically.   The failure mode timings are defined in watchdog.sh.
The watchdog is only enabled if the file <controller root>/HA/WATCHDOG_ENABLE
exists. Removing the file causes the watchdog to exit.

to enable the watchdog, as root:
	touch <controller root>/HA/WATCHDOG_ENABLE
	chmod 777 <controller root>/HA/WATCHDOG_ENABLE
	service appdcontroller start

running the replicate.sh script with the -w option at final activation will 
create the watchdog control file automatically.

Assassin:
---------
After a failover, it is possible that the old primary may come online.  If this
occurs, the load balancer may send load to the old primary.  To prevent this,
the new primary continually polls the old primary and if it becomes accessible,
kills it and inhibits it from starting again.

Failover:
---------
A manual failover can be triggered by running failover.sh on the secondary.
This will kill the watchdog and activate the database.  it will also try to
assassinate the old primary.
This only happens if replication is broken. if replication is good, we just
deactivate the other appserver and activation this one, while leaving the db
up.  this case also does not fire up the assassin.

Logging:
--------
the logs directory contains several status and progress logs of the various components.

Best Practices:
---------------
If possible, a dedicated network connection should be provisioned between the
HA pair.  this set of interfaces should be the ones placed into the /etc/hosts
files, and used as the argument for the -s option to the replicate.sh script.

Backups are best done by stopping the appdcontroller service on the secondary
and performing a file-level copy of the appdynamics directories.  these can
be incremental or complete, depending on the reliability of your solution.
when the backup is done, simply start the service; replication will catch up
and guarantee the integrity of your data.

A load balancer can probe http://<controller>:<port>/rest/serverstatus
to determine which of the two controllers is active. the active node will
return a HTTP 200.

should it be necessary to have a hook in the failover process, for example to update 
a dynamics DNS service or to notify a load balancer or proxy, the failover.sh script 
is the place to add code.

Version:
--------
$Id: README 1.9 2015-12-23 00:36:28 cmayer Exp $

